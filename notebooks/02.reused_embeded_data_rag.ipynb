{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a339c5",
   "metadata": {},
   "source": [
    "# Skip Reindexing and Reuse Saved Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5dc3f2",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook, we will skip the embedding generation and re-indexing process by loading previously saved document embeddings and metadata from a JSON file. We will then use this data to directly query Elasticsearch and the RetrievalQA chain.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7455d4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings and metadata from JSON.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the saved embeddings and metadata\n",
    "with open('document_embeddings.json', 'r') as f:\n",
    "    saved_data = json.load(f)\n",
    "\n",
    "# Extract texts, embeddings, and metadata\n",
    "texts = [item['text'] for item in saved_data]\n",
    "embeddings = [np.array(item['embedding']) for item in saved_data]\n",
    "metadatas = [item['metadata'] for item in saved_data]\n",
    "\n",
    "print(\"Loaded embeddings and metadata from JSON.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66186118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'fcra_chunks' already exists in Elasticsearch. No re-indexing required.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Elasticsearch connection\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'scheme': 'http'}])\n",
    "index_name = 'fcra_chunks'\n",
    "\n",
    "# Check if the index already exists\n",
    "if es.indices.exists(index=index_name):\n",
    "    print(f\"Index '{index_name}' already exists in Elasticsearch. No re-indexing required.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' does not exist. Re-indexing is required.\")\n",
    "    index_name = 'fcra_chunks'\n",
    "\n",
    "    # Delete the index if it already exists (optional)\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "\n",
    "    # Define the mapping\n",
    "    mapping = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"embedding\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": 1536\n",
    "                },\n",
    "                \"text\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"metadata\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"enabled\": True\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create the index with the mapping\n",
    "    es.indices.create(index=index_name, body=mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a08c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the embedding model with the API key\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6b0327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bs/rk6rcnf923l4k8xms3k927hr0000gn/T/ipykernel_9552/330155363.py:12: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class ElasticSearchRetriever(BaseRetriever, BaseModel):\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM (GPT)\n",
    "llm = OpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Create a Custom Retriever Using Elasticsearch\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.schema import BaseRetriever\n",
    "from typing import Any, List\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class ElasticSearchRetriever(BaseRetriever, BaseModel):\n",
    "    es: Any\n",
    "    index_name: str\n",
    "    embedding_model: Any\n",
    "    k: int = 5\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # Generate and normalize the query embedding\n",
    "        query_embedding = self.embedding_model.embed_query(query)\n",
    "        query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "\n",
    "        # Build the script score query\n",
    "        script_query = {\n",
    "            \"size\": self.k,\n",
    "            \"query\": {\n",
    "                \"script_score\": {\n",
    "                    \"query\": {\"match_all\": {}},\n",
    "                    \"script\": {\n",
    "                        \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
    "                        \"params\": {\n",
    "                            \"query_vector\": query_embedding.tolist()\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"_source\": [\"text\", \"metadata\"]\n",
    "        }\n",
    "\n",
    "        # Execute the search\n",
    "        response = self.es.search(index=self.index_name, body=script_query)\n",
    "\n",
    "        # Convert hits to Documents\n",
    "        docs = []\n",
    "        for hit in response['hits']['hits']:\n",
    "            doc = Document(\n",
    "                page_content=hit['_source']['text'],\n",
    "                metadata=hit['_source']['metadata']\n",
    "            )\n",
    "            docs.append(doc)\n",
    "        return docs\n",
    "\n",
    "# Initialize the Retriever\n",
    "retriever = ElasticSearchRetriever(\n",
    "    es=es,\n",
    "    index_name=index_name,\n",
    "    embedding_model=embedding_model,\n",
    "    k=5  # Number of documents to retrieve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba57c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RetrievalQA chain using the from_chain_type method\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define a custom prompt template that encourages the model to use only the retrieved documents\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant that answers questions based only on the following documents:\n",
    "\n",
    "{context}\n",
    "\n",
    "If the answer is not in the documents, respond with \"I don't know based on the information provided.\"\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Create a prompt object using the custom prompt template\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "753d7b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "Answer: The key provisions of the FCRA include: 1) providing consumers with rights to access and correct their data held by consumer reporting agencies, 2) imposing obligations on consumer reporting agencies to protect consumer data and maintain accuracy, 3) imposing duties on users of consumer reports to adhere to permissible purpose requirements, 4) defining the class of data regulated under the law as consumer reports, and 5) regulating the disposal of records containing consumer information.\n"
     ]
    }
   ],
   "source": [
    "# Run a test query\n",
    "query = \"What are the key provisions of the FCRA?\"\n",
    "# query = \"What is the capital city of France?\"\n",
    "\n",
    "answer = qa_chain.run(query)\n",
    "print(\"Answer:\", answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What are the permissible purposes for obtaining a consumer report?\",\n",
    "    \"Explain the dispute process under the FCRA. Which module did you used to answer this question?\",\n",
    "    \"What obligations do credit reporting agencies have according to the FCRA? Which module did you used to answer this question?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    answer = qa_chain.run(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
