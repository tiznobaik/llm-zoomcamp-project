{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a339c5",
   "metadata": {},
   "source": [
    "# Skip Reindexing and Reuse Saved Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5dc3f2",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook, we will skip the embedding generation and re-indexing process by loading previously saved document embeddings and metadata from a JSON file. We will then use this data to directly query Elasticsearch and the RetrievalQA chain.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7455d4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings and metadata from JSON.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the saved embeddings and metadata\n",
    "with open('document_embeddings.json', 'r') as f:\n",
    "    saved_data = json.load(f)\n",
    "\n",
    "# Extract texts, embeddings, and metadata\n",
    "texts = [item['text'] for item in saved_data]\n",
    "embeddings = [np.array(item['embedding']) for item in saved_data]\n",
    "metadatas = [item['metadata'] for item in saved_data]\n",
    "\n",
    "print(\"Loaded embeddings and metadata from JSON.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66186118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'fcra_chunks' already exists in Elasticsearch. No re-indexing required.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Elasticsearch connection\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'scheme': 'http'}])\n",
    "index_name = 'fcra_chunks'\n",
    "\n",
    "# Check if the index already exists\n",
    "if es.indices.exists(index=index_name):\n",
    "    print(f\"Index '{index_name}' already exists in Elasticsearch. No re-indexing required.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' does not exist. Re-indexing is required.\")\n",
    "    # Add code for reindexing if needed (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a08c8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bs/rk6rcnf923l4k8xms3k927hr0000gn/T/ipykernel_15191/3451141637.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
     ]
    }
   ],
   "source": [
    "#  Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the embedding model with the API key\n",
    "embedding_model = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b6b0327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bs/rk6rcnf923l4k8xms3k927hr0000gn/T/ipykernel_15191/4229264796.py:9: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class ElasticSearchRetriever(BaseRetriever, BaseModel):\n"
     ]
    }
   ],
   "source": [
    "# Create a Custom Retriever Using Elasticsearch\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.schema import BaseRetriever\n",
    "from typing import Any, List\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class ElasticSearchRetriever(BaseRetriever, BaseModel):\n",
    "    es: Any\n",
    "    index_name: str\n",
    "    embedding_model: Any\n",
    "    k: int = 5\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # Generate and normalize the query embedding\n",
    "        query_embedding = self.embedding_model.embed_query(query)\n",
    "        query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "\n",
    "        # Build the script score query\n",
    "        script_query = {\n",
    "            \"size\": self.k,\n",
    "            \"query\": {\n",
    "                \"script_score\": {\n",
    "                    \"query\": {\"match_all\": {}},\n",
    "                    \"script\": {\n",
    "                        \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
    "                        \"params\": {\n",
    "                            \"query_vector\": query_embedding.tolist()\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"_source\": [\"text\", \"metadata\"]\n",
    "        }\n",
    "\n",
    "        # Execute the search\n",
    "        response = self.es.search(index=self.index_name, body=script_query)\n",
    "\n",
    "        # Convert hits to Documents\n",
    "        docs = []\n",
    "        for hit in response['hits']['hits']:\n",
    "            doc = Document(\n",
    "                page_content=hit['_source']['text'],\n",
    "                metadata=hit['_source']['metadata']\n",
    "            )\n",
    "            docs.append(doc)\n",
    "        return docs\n",
    "\n",
    "# Initialize the Retriever\n",
    "retriever = ElasticSearchRetriever(\n",
    "    es=es,\n",
    "    index_name=index_name,\n",
    "    embedding_model=embedding_model,\n",
    "    k=5  # Number of documents to retrieve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "753d7b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bs/rk6rcnf923l4k8xms3k927hr0000gn/T/ipykernel_15191/3825728049.py:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
      "/var/folders/bs/rk6rcnf923l4k8xms3k927hr0000gn/T/ipykernel_15191/3825728049.py:13: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  \n",
      "The key provisions of the FCRA include:\n",
      "1. Providing consumers with rights to access and correct data about them held by Consumer Reporting Agencies (CRAs)\n",
      "2. Imposing obligations on CRAs to protect consumer data and adhere to permissible purpose requirements\n",
      "3. Defining the class of data that is regulated under the law as information used for determining consumer eligibility for household credit, insurance, employment, or any other permissible purpose\n",
      "4. Requiring proper disposal of records by entities covered under the law, such as the Federal Trade Commission and other federal agencies.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the LLM (GPT)\n",
    "llm = OpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\",  # You can change to map_reduce, etc.\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "# Run a test query\n",
    "query = \"What are the key provisions of the FCRA?\"\n",
    "answer = qa_chain.run(query)\n",
    "print(\"Answer:\", answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d6dd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the permissible purposes for obtaining a consumer report?\n",
      "Answer:  The permissible purposes for obtaining a consumer report include determining eligibility for credit, insurance, government benefits, renting an apartment, opening a bank account, or cashing a check. Additionally, a consumer may also initiate a transaction or have an account with an entity that will use the consumer report for a legitimate business need. Other purposes are not considered permissible and include law enforcement, marketing, or similar reasons.\n",
      "------\n",
      "Query: Explain the dispute process under the FCRA. Which module did you used to answer this question?\n",
      "Answer:  I don't know which module specifically discusses the dispute process under the FCRA, but it is mentioned throughout the course. The dispute process under the FCRA allows consumers to dispute any inaccurate or incomplete information in their consumer reports with the consumer reporting agency. The agency must then investigate the dispute and correct any errors within a reasonable amount of time. This process is discussed in detail in Module 11: Disputes and Reinvestigation.\n",
      "------\n",
      "Query: What obligations do credit reporting agencies have according to the FCRA? Which module did you used to answer this question?\n",
      "Answer:  According to the FCRA, credit reporting agencies have the obligation to protect consumer data, adhere to \"permissible purpose\" requirements, and maintain reasonable data accuracy. This information can be found in Module 4: Consumer Reporting Agencies.\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What are the permissible purposes for obtaining a consumer report?\",\n",
    "    \"Explain the dispute process under the FCRA. Which module did you used to answer this question?\",\n",
    "    \"What obligations do credit reporting agencies have according to the FCRA? Which module did you used to answer this question?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    answer = qa_chain.run(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb68a804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
